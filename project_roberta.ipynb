{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c4044e",
   "metadata": {},
   "source": [
    "Mental Health Classification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f648753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "label_map = {\n",
    "    \"Normal\": 0,\n",
    "    \"Depression\": 1,\n",
    "    \"Suicidal\": 2,\n",
    "    \"Anxiety\": 3,\n",
    "    \"Stress\": 4,\n",
    "    \"Bipolar\": 5,\n",
    "    \"Personality Disorder\": 6\n",
    "}\n",
    "\n",
    "\n",
    "db = pd.read_csv('Sentiment_analysis_dataset(in).csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84503945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in dataset: ['Depression' 'Stress' 'Normal' 'Suicidal' 'Anxiety'\n",
      " 'Personality disorder' 'Bipolar' nan]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in dataset:\", db['Status'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "85ded796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Statement      Status\n",
      "0   life doesn’t feel worth it that’s kind of it? ...  Depression\n",
      "1   this life sucks and if it were for my religiou...  Depression\n",
      "2   its been 9 months now for our marriage and she...      Stress\n",
      "3   i do not feel particularly sad or anxious or a...  Depression\n",
      "4   i am taking venlafaxine. it is an ssri. does n...  Depression\n",
      "5   i (17m) have come to the realisation that my d...  Depression\n",
      "6   been on fluoxetine for year but anyway there s...  Depression\n",
      "7   even a four day week seems too long i want to ...      Normal\n",
      "8   i often had suicidal thoughts, recently, with ...    Suicidal\n",
      "9   this is the first time facing pisces. extro pa...      Normal\n",
      "10  being an orphan at your early stages of life b...  Depression\n",
      "11  the dread of thinking you have cancer... again...     Anxiety\n",
      "12  i (30f) married my husband (31m) about 6 month...      Stress\n",
      "13           what day is eid al-fitr if you may know?      Normal\n",
      "14  free counseling and support for anyone struggl...     Anxiety\n",
      "15  i am a joke, no friends, everyone thinks i am ...    Suicidal\n",
      "16  yet he says hes ready to go, nobody wants him ...    Suicidal\n",
      "17  @jonathanrknight aww that's really sweet of yo...      Normal\n",
      "19  i have been in a very toxic relationship where...    Suicidal\n",
      "20  if you live alone and no one checks on you, wh...    Suicidal\n"
     ]
    }
   ],
   "source": [
    "db = db.dropna(subset=['Statement', 'Status'])\n",
    "db['Status'] = db['Status'].str.strip().str.title()\n",
    "db['Statement'] = db['Statement'].apply(lambda x: x.lower())\n",
    "unmapped = set(db['Status'].unique()) - set(label_map.keys())\n",
    "if unmapped:\n",
    "    print(\"Warning: These labels aren't in your map:\", unmapped)\n",
    "    db = db[db['Status'].isin(label_map.keys())]\n",
    "\n",
    "statement = db['Statement'].tolist()\n",
    "status = db['Status'].tolist()\n",
    "\n",
    "print(db.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71a77e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [np.float64(3.232876712328767), np.float64(3.41316672451695), np.float64(4.895453036840358), np.float64(13.746505125815471), np.float64(20.26098901098901), np.float64(19.407894736842106), np.float64(50.513698630136986)]\n"
     ]
    }
   ],
   "source": [
    "train_label_counts = train_labels.value_counts().sort_index()\n",
    "total = train_label_counts.sum()\n",
    "class_weights = [total / train_label_counts[lbl] for lbl in label_map.keys()]\n",
    "print(\"Class Weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "614e93c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):  # 👈 accepts any extra arguments\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "\n",
    "        weight = torch.tensor([\n",
    "            3.23, 3.41, 4.89, 13.75, 20.26, 19.41, 50.51  # whatever your final class weights are\n",
    "        ], dtype=torch.float32).to(logits.device)\n",
    "\n",
    "        loss_fct = CrossEntropyLoss(weight=weight)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f0fc530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data size: 29500\n",
      "Testing data size: 7375\n"
     ]
    }
   ],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(db['Statement'], db['Status'], test_size=0.2, random_state=42)\n",
    "\n",
    "train_labels = train_labels.reset_index(drop=True)\n",
    "val_labels = val_labels.reset_index(drop=True)\n",
    "\n",
    "print(f\"training data size: {len(train_texts)}\")\n",
    "print(f\"Testing data size: {len(val_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c12e7c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label distribution:\n",
      " Status\n",
      "Normal                  9125\n",
      "Depression              8643\n",
      "Suicidal                6026\n",
      "Anxiety                 2146\n",
      "Bipolar                 1520\n",
      "Stress                  1456\n",
      "Personality Disorder     584\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Validation label distribution:\n",
      " Status\n",
      "Normal                  2315\n",
      "Depression              2140\n",
      "Suicidal                1429\n",
      "Anxiety                  545\n",
      "Bipolar                  421\n",
      "Stress                   353\n",
      "Personality Disorder     172\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Training label distribution:\\n\", train_labels.value_counts())\n",
    "print(\"\\nValidation label distribution:\\n\", val_labels.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e10e03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_texts type: <class 'list'>\n",
      "train_texts[0] type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# Make sure the texts are strings\n",
    "train_texts = train_texts.astype(str).tolist()\n",
    "val_texts = val_texts.astype(str).tolist()\n",
    "\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Debug print\n",
    "print(\"train_texts type:\", type(train_texts))         # should be list\n",
    "print(\"train_texts[0] type:\", type(train_texts[0]))   # should be str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12692a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i want everyone to feel my pain i am sick of everyone trying to hold me down and take advantage of mei amsick of always being second choicei amsick of being neglected feared and hated i want everyone to feel my wrath and my pain i am sick of hiding in the shadows and just taking it all i want everything they ever did to me to happen to them and 100 times over i hope they never get reliefi amsick of people and i am not afraid to admit it and it makes me sick to see so many happy people with perfect lives they dont deserve it if i cant be happy why should anyone else be', 'home. had uni today, got results back :hd, yehhh! its been 3 yrs, why am i always thinking of the wat ifs?', 'really? why?', 'i am not sure how much longer i can last. i always was a fighter but i think the straw has broken the camels back. where do i go from here? i think its getting close to that time for me to make the decision. the trauma is too great. people fucking suck. and i cannot burden these feelings on my friends. i really tried my best', 'i feel so trapped in my mind, the feeling that i will never be normal or see things the right way is torture. all i want is to fit in, and people that understand me. i have level 2 aspergers, which leads to constantly bullying, being excluded, and always being the odd one out.. i cannot live like this and might od soon. free me out of my autistic head. autism is a hellhole, i am so ashamed.']\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95efd8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MentalHealthDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels, label_map):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.label_map = label_map\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        label = self.labels.iloc[idx]\n",
    "        #item[\"labels\"] = torch.tensor(self.label_map[idx])\n",
    "        item[\"labels\"] = torch.tensor(self.label_map[label])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = MentalHealthDataset(train_encodings, train_labels, label_map)\n",
    "val_dataset = MentalHealthDataset(val_encodings, val_labels, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bba1febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels = 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9ce8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",                       # Where to save model checkpoints\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",                  # <--- Corrected!\n",
    "    save_strategy=\"epoch\",                        # Save model at end of each epoch\n",
    "    logging_strategy=\"epoch\",                     # Log metrics at end of each epoch\n",
    "    learning_rate=2e-5,                           # Good default for RoBERTa\n",
    "    weight_decay=0.01,                            # Slight regularization\n",
    "    load_best_model_at_end=True,                  # Load the best model (based on eval loss)\n",
    "    metric_for_best_model=\"accuracy\",             # If using compute_metrics (below)\n",
    "    save_total_limit=2,                           # Keep only 2 checkpoints to save space\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75bc7cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3866' max='11064' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3866/11064 25:51:40 < 48:10:30, 0.04 it/s, Epoch 1.05/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.725800</td>\n",
       "      <td>0.568571</td>\n",
       "      <td>0.827797</td>\n",
       "      <td>0.828612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#trainer.train(resume_from_checkpoint=True)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2560\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2553\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2554\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2555\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2556\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2557\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2558\u001b[0m )\n\u001b[0;32m   2559\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2560\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2563\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2564\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2565\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2566\u001b[0m ):\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2568\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:3782\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3779\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   3780\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 3782\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:2454\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2453\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2454\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    625\u001b[0m     )\n\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#trainer.train(resume_from_checkpoint=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9abc9f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf286cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./model\"\n",
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(model_path)\n",
    "trainer.save_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b32204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    labels = pred.label_ids\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average='weighted')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "075bb364",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91e68088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def predict_label(text, model, tokenizer, label_map):\n",
    "    id2label = {v: k for k, v in label_map.items()}  # safe reverse map\n",
    "    \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "\n",
    "    predicted_label_id = torch.argmax(probs, dim=1).item()\n",
    "    label_name = id2label[predicted_label_id]  # ← safe lookup\n",
    "\n",
    "    return label_name, probs.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "beb87dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: I am so stressed out and tired. I'm so done\n",
      "Predicted Label: Bipolar\n",
      "---\n",
      "Input: Life is so empty and hopeless\n",
      "Predicted Label: Personality Disorder\n",
      "---\n",
      "Input: I'm fine. Nice weather today!\n",
      "Predicted Label: Personality Disorder\n",
      "---\n",
      "Input: I have so much homework I'm gonna fail my class.\n",
      "Predicted Label: Personality Disorder\n",
      "---\n",
      "Input: My dog died. Life has become dull and I'm really sad.\n",
      "Predicted Label: Bipolar\n",
      "---\n",
      "Input: I'm always mad or sad what the hell.\n",
      "Predicted Label: Personality Disorder\n",
      "---\n",
      "Input: sometimes i hear voices and they confuse me\n",
      "Predicted Label: Personality Disorder\n",
      "---\n",
      "Input: I'm depressed\n",
      "Predicted Label: Bipolar\n",
      "---\n",
      "Input: I'm anxious\n",
      "Predicted Label: Personality Disorder\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "test_statements = [\n",
    "    \"I am so stressed out and tired. I'm so done\",\n",
    "    \"Life is so empty and hopeless\",\n",
    "    \"I'm fine. Nice weather today!\",\n",
    "    \"I have so much homework I'm gonna fail my class.\",\n",
    "    \"My dog died. Life has become dull and I'm really sad.\",\n",
    "    \"I'm always mad or sad what the hell.\",\n",
    "    \"sometimes i hear voices and they confuse me\",\n",
    "    \"I'm depressed\",\n",
    "    \"I'm anxious\"\n",
    "]\n",
    "\n",
    "for text in test_statements:\n",
    "    label, _ = predict_label(text, model, tokenizer, label_map)\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Predicted Label: {label}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe7b8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='52' max='922' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 52/922 03:54 < 1:06:41, 0.22 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:4154\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[1;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4151\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m   4153\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[1;32m-> 4154\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4155\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4157\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[0;32m   4158\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[0;32m   4159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   4160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4162\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4164\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[0;32m   4165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:4348\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   4345\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[0;32m   4347\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[1;32m-> 4348\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4349\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4350\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4352\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\trainer.py:4564\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   4562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[0;32m   4563\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 4564\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   4565\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m   4567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "Cell \u001b[1;32mIn[101], line 7\u001b[0m, in \u001b[0;36mCustomTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, inputs, return_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m         labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m         logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogits\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m         weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\n\u001b[0;32m     10\u001b[0m             \u001b[38;5;241m3.232876712328767\u001b[39m,\n\u001b[0;32m     11\u001b[0m             \u001b[38;5;241m3.41316672451695\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;241m50.513698630136986\u001b[39m\n\u001b[0;32m     17\u001b[0m ], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(logits\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:1322\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1314\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1322\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1333\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1334\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:978\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m    976\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m--> 978\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    987\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    989\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    990\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    991\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:631\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    620\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    621\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    622\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         output_attentions,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    641\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:562\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    559\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[1;32m--> 562\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[0;32m    567\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:574\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[1;34m(self, attention_output)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[1;32m--> 574\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:472\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 472\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[0;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dec33e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1dbfde7d160>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "preds_output = trainer.predict(val_dataset)\n",
    "\n",
    "y_pred = np.argmax(preds_output.predictions, axis=1)\n",
    "y_true = preds_output.label_ids\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(label_map.keys()))\n",
    "disp.plot(xticks_rotation=45)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
